%% LyX 2.0.2 created this file.  For more info, see http://www.lyx.org/.
%% Do not edit unless you really know what you are doing.
\documentclass[british]{report}
\usepackage{helvet}
\renewcommand{\familydefault}{\sfdefault}
\usepackage[T1]{fontenc}
\usepackage[latin9]{inputenc}
\usepackage{geometry}
\geometry{verbose,tmargin=3cm,bmargin=3cm,lmargin=2cm,rmargin=2cm}
\setcounter{secnumdepth}{3}
\setcounter{tocdepth}{3}
\usepackage{array}
\usepackage{float}
\usepackage{wrapfig}
\usepackage{url}
\usepackage{multirow}
\usepackage{amsmath}
\usepackage{graphicx}
\usepackage{setspace}
\usepackage{nomencl}
% the following is useful when we have the old nomencl.sty package
\providecommand{\printnomenclature}{\printglossary}
\providecommand{\makenomenclature}{\makeglossary}
\makenomenclature
\doublespacing

\makeatletter

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% LyX specific LaTeX commands.
%% Because html converters don't know tabularnewline
\providecommand{\tabularnewline}{\\}
\floatstyle{ruled}
\newfloat{algorithm}{tbp}{loa}[chapter]
\providecommand{\algorithmname}{Algorithm}
\floatname{algorithm}{\protect\algorithmname}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% User specified LaTeX commands.
\let\originaltabular\tabular
\let\endoriginaltabular\endtabular
\renewenvironment{tabular}[1]{%
  \begingroup%
  \centering%
  \originaltabular{#1}}%
  {\endoriginaltabular\endgroup}

\let\originaltable\table
\let\endoriginaltable\endtable
\renewenvironment{table}[1][ht]{%
  \originaltable[#1]
  \centering}%
  {\endoriginaltable}

\let\originalfigure\figure
\let\endoriginalfigure\endfigure
\renewenvironment{figure}[1][ht]{%
  \originalfigure[#1]
  \centering}%
  {\endoriginalfigure}

\makeatother

\usepackage{babel}
\begin{document}

\chapter{Developing the analysis of e4C data \label{chap:e4C-Analysis}}


\section{Introduction}

Explain the context of when this work was done, that there was little
if any published work on how to analyse this data. Mention other analysis
work that has come out subsequently (eg. Amos Tanay) and how that
fits around what I\textquoteright{}ve done.


\section{Initial data handling}

All of the e4C libraries discussed were sequenced using the Illumina
Genome Analyser IIx. Initial data processing up to the point of a
SeqMonk library was done by the Babraham Bioinformatics team, primarily
Dr. Felix Krueger and Dr. Simon Andrews.


\subsection{Bareback processing}

Illumina next generation sequencing machine such as the Genome Analyser
IIx 'sequence by synthesis'. Libraries are hybridised to oligonucleotides
on a chip and clusters are generated surrounding each library sequence
with multiple rounds of amplification. Fluorescent bases are then
added one by one, and the chip imaged each round. The colour information
collected in the image can be used to determine the base being added
to the cluster according to its colour, and so the sequence of each
cluster is determined.

Central to this technique is the process of calling cluster locations,
typically done by the Illumina Sequence Control Software (\nomenclature{SCS}{Illumina Sequence Control Software}SCS)
with Real Time Analysis (\nomenclature{RTA}{Illumina Real Time Analysis}RTA)
once the first fluorescent base is added. Once determined, the cluster
positions are used for the remaining base pair calling. If the cluster
density on the chip is large, then spots can start to merge. This
isn't a problem with a typical Illumina library, as the different
spots will usually be different colours, and so discernable from each
other. However, every sequence within e4C libraries begins with a
barcode region followed by the restriction enzyme recognition sequence.
This lack of diversity within the first bases of the sequence can
cause problems for the cluster calling; merged clusters may be called
as one which can be thrown out by the purity filter because of its
size, or rejected later when the sequence diverges and it starts to
exhibit mixed fluorescence signals. This has the effect of a vastly
reduced number of reads being processed (Fig \ref{fig:Bareback-overview}).
The same effect can happen in multiplexed libraries using barcodes
to identify different samples on the same chip.

This problem was first experienced in our institute with Dr. Cameron
Osborne's e4C libraries, and also strongly affected my sequencing
runs. To overcome the initial lack of diversity, Dr. Felix Krueger
and Dr. Simon Andrews of the Babraham bioinformatics department developed
a package called \emph{Bareback} (barcode back-processing) \cite{Krueger2011}.
Bareback uses the raw image files generated by the Genome Analyser
IIx and moves the images taken during low diversity to the back of
the stack by renaming the files. These are then analysed using the
Illumina \nomenclature{GOAT}{Illumina General Oligo Analysis Tool}GOAT
(General Oligo Analysis Tool) pipeline, now part of the Illumina \nomenclature{OLB}{Illumina Off-Line Basecaller}OLB
(Off-Line basecaller).

Bareback processing greatly increased the number of sequence reads
returned from my e4C libraries (Table \ref{tab:bareback-stats}),
completely resucing one library with particularly dense clusters from
which the standard SCS processing returned no reads.

\begin{figure}
\includegraphics[width=0.7\columnwidth]{\string"figures/chapter 5/bareback/bareback\string".pdf}

\caption{\label{fig:Bareback-overview}Bareback overview}


Taken from Kreuger \emph{et al.} (2001) \cite{Krueger2011}
\end{figure}


\begin{table}
\begin{tabular}{|l|c|c|c|}
\cline{2-4} 
\multicolumn{1}{l|}{} & \textbf{Illumina SCS processing} & \textbf{Bareback processing} & \textbf{Fold increase}\tabularnewline
\hline 
June 2010 - BCR and MLL & 14,409,580 & 22,167,823 & 1.54\tabularnewline
\hline 
Sept 2010 - MLL & 13,147,751 & 16,704,073 & 1.27\tabularnewline
\hline 
Oct 2010 - BCR and MLL & 18,434,991 & 23,251,377 & 1.26\tabularnewline
\hline 
Dec 2010 - MLL1 & 4,690,956 & 27,868,955 & 5.94\tabularnewline
\hline 
Dec 2010 - MLL2 & 272,927 & 30,632,135 & 112.24\tabularnewline
\hline 
Dec 2010 - ABL & 0 & 33,157,523 & $\infty$\tabularnewline
\hline 
Dec 2010 - MLL phiX & 24,349,038 & 26,284,182  & 1.08\tabularnewline
\hline 
\end{tabular}

\caption{\label{tab:bareback-stats}Illumina sequence processing statistics
with Bareback}


\end{table}



\subsection{Quality control}

Once sequences had been produced by the Bareback processing, the quality
of the sequence data was assessed using two tools written by Dr. Simon
Andrews of the Babraham bioinformatics department, \emph{FastQC} and
\emph{FastQ Analysis}. I was involved in development of FastQC version
0.9.3 (released 16/6/11) by contributing a new CSS theme to the report
structure allowing simultaneous viewing of the overview navigation
and report results.

All e4C libraries passed the quality control steps without any cause
for concern. Representative results are shown in Figure \ref{fig:e4C-Library-FastQC}.

\begin{figure}


\caption{\label{fig:e4C-Library-FastQC}Representative e4C Library FastQC and
FastQ Analysis}
\end{figure}



\subsection{Sequence trimming}

\begin{wrapfigure}{O}{0.4\columnwidth}%
\includegraphics[width=0.3\columnwidth]{\string"figures/chapter 5/e4C sequence structure/e4C sequence structure\string".pdf}

\caption{\label{fig:e4C-library-structure}Expected structure of reads in each
e4C library}
\end{wrapfigure}%


The expected structure of each e4C read is a barcode region specific
to each library, an \emph{AseI} recognition site and then unknown
partner sequence representing the adjacent DNA fragment in the 3C
library (Fig \ref{fig:e4C-library-structure}, Table \ref{tab:e4C-primers}).
In a small proportion of cases, we expected to then see either a second
\emph{AseI} recognition site followed by a third interaction partner,
or an \emph{NlaIII} recognition site followed by Illumina adapter
sequence.

Over 97\% of the sequences from each sequencing run started with an
expected barcode sequence, with the exception of the \emph{MLL} Run
3 phiX run. For this library, an e4C library was spiked into a phiX
control lane and the two sequencing primers were added to the same
lane. Unfortunately, more than 95\% of the library reads were sequenced
by the Illumina PE Ad 1.0 primer instead of the custom sequencing
primer. Sequences with this primer gave just the bait sequence with
3 bp of unknown parter sequence.

To pre-process the e4C library reads, Dr. Felix Kreuger in the Babraham
Bioinformatics group wrote a script in Perl, which I later modified
and used myself (Appendix \ref{sec:APP-library-trimming-script}).
The script goes through the FastQ file and checks the first three
base pairs of each sequence to see if it matches the barcode. If so,
it trims them off and looks to see if the next six base pairs are
an AseI recognition site (ATTAAT). Next, the script searches for \emph{AseI}
and \emph{NlaIII} sites. If a second \emph{AseI} site is found the
line is rejected, if a \emph{NlaIII} site is found the sequence is
trimmed to that site. If the remaining sequence is less than 25 bp
long it is rejected. The remaining content in the FastQ read, such
as quality scores, are trimmed to the same length and the line is
printed to the output file. The processing statistics from the e4C
libraries can be seen in table \ref{tab:Library-trimming-statistics}.

\begin{table}
\begin{tabular}{|>{\raggedright}m{2cm}|>{\raggedleft}m{2cm}|>{\raggedleft}m{2cm}|>{\raggedleft}m{2cm}|>{\raggedleft}m{2cm}|>{\raggedleft}m{2cm}|>{\raggedleft}m{2cm}|}
\hline 
 & {\scriptsize Reads starting with correct barcode} & {\scriptsize Reads with second }\emph{\scriptsize AseI}{\scriptsize{}
site (discarded)} & {\scriptsize Reads with }\emph{\scriptsize NlaIII}{\scriptsize{} site
(too short to be mapped)} & {\scriptsize Reads with }\emph{\scriptsize NlaIII}{\scriptsize{} site
(long enough to be mapped)} & {\scriptsize Total sequences to be mapped} & {\scriptsize Aligned reads}\tabularnewline
\hline 
\hline 
\emph{\scriptsize BCR}{\scriptsize{} Run 1} & {\scriptsize 22390498} & {\scriptsize 85448 (0.4\%)} & {\scriptsize 3823824 (17.1\%)} & {\scriptsize 2860849 (12.8\%)} & {\scriptsize 18203128 (81.3\%)} & {\scriptsize 14931033 (66.7\%) }\emph{\scriptsize (82.0\%)}\tabularnewline
\hline 
\emph{\scriptsize BCR}{\scriptsize{} Run 2} & {\scriptsize 12616122} & {\scriptsize 41823 (0.3\%)} & {\scriptsize 1493641 (11.8\%)} & {\scriptsize 1146963 (9.1\%)} & {\scriptsize 10932276 (86.7\%)} & {\scriptsize 9260876 (73.4\%) }\emph{\scriptsize (84.7\%)}\tabularnewline
\hline 
\emph{\scriptsize MLL}{\scriptsize{} Run 1} & {\scriptsize 55868} & {\scriptsize 15 (0.03\%)} & {\scriptsize 29279 (52.4\%)} & {\scriptsize 1819 (3.3\%)} & {\scriptsize 26129 (46.8\%)} & {\scriptsize 21923 (39.2\%) }\emph{\scriptsize (83.9\%)}\tabularnewline
\hline 
\emph{\scriptsize MLL}{\scriptsize{} Run 2} & {\scriptsize 16442664} & {\scriptsize 45012 (0.03\%)} & {\scriptsize 1388307 (8.4\%)} & {\scriptsize 662684 (4.0\%)} & {\scriptsize 14950490 (90.9\%)} & {\scriptsize 13535278 (82.3\%) }\emph{\scriptsize (90.5\%)}\tabularnewline
\hline 
\emph{\scriptsize MLL}{\scriptsize{} Run 3} & {\scriptsize 9960249} & {\scriptsize 1535 (0.02\%)} & {\scriptsize 557742 (5.6\%)} & {\scriptsize 450422 (4.5\%)} & {\scriptsize 9368936 (94.1\%)} & {\scriptsize 8498056 (85.3\%) }\emph{\scriptsize (90.7\%)}\tabularnewline
\hline 
\emph{\scriptsize MLL}{\scriptsize{} Run 3 phiX} & {\scriptsize 56994} & {\scriptsize 321 (0.6\%)} & {\scriptsize 1974 (3.5\%)} & {\scriptsize 1983 (3.5\%)} & {\scriptsize 48952 (85.9\%)} & {\scriptsize 44194 (77.5\%) }\emph{\scriptsize (90.3\%)}\tabularnewline
\hline 
\emph{\scriptsize ABL}{\scriptsize{} Run 1} & {\scriptsize 32140483} & {\scriptsize 434554 (1.4\%)} & {\scriptsize 201658 (0.6\%)} & {\scriptsize 988675 (3.1\%)} & {\scriptsize 31082375 (96.7\%)} & {\scriptsize }\tabularnewline
\hline 
\emph{\scriptsize MLL}{\scriptsize{} Promoter 1} & {\scriptsize 27548835} & {\scriptsize 243399 (0.9\%)} & {\scriptsize 485996 (1.8\%)} & {\scriptsize 1124315 (4.1\%)} & {\scriptsize 26290533 (95.4\%)} & \tabularnewline
\hline 
\emph{\scriptsize MLL}{\scriptsize{} Promoter 2} & {\scriptsize 30333263} & {\scriptsize 232741 (0.8\%)} & {\scriptsize 1917547 (6.3\%)} & {\scriptsize 1875757 (6.2\%)} & {\scriptsize 27748869 (91.5\%)} & \tabularnewline
\hline 
\end{tabular}

\caption{\label{tab:Library-trimming-statistics}Library trimming statistics}


Percentage of possible sequences that were successfully aligned are
shown in italics.
\end{table}



\subsection{Sequence alignment}

The resulting trimmed reads were next passed through the genome alignment
tool \emph{Bowtie} \cite{Langmead2009}. Reads were aligned with 82\%
- 92\% efficiency (Table \ref{tab:Library-trimming-statistics}).The
following parameters were used, as explained in Table \ref{tab:explanation-of-bowtie-parameters}:

\begin{algorithm}[h]
\texttt{\small bowtie -q -{}-phred64-quals -p 8 -m 1 hg19 <trimmed\_reads.txt>
<output\_alignment.bowtie>}{\small \par}

\caption{Bowtie alignment parameters}
\end{algorithm}


\begin{table}[h]
\begin{tabular}{|c|l|}
\hline 
{\scriptsize Parameter} & {\scriptsize Description}\tabularnewline
\hline 
\hline 
{\scriptsize -q} & {\scriptsize Input is in FastQ format}\tabularnewline
\hline 
{\scriptsize --phred64-quals} & {\scriptsize Correct interpretation of ASCII quality scores}\tabularnewline
\hline 
{\scriptsize -p 8} & {\scriptsize Use eight CPU cores for the alignment}\tabularnewline
\hline 
{\scriptsize -m 1} & {\scriptsize Ignore any read with more than one alignment}\tabularnewline
\hline 
{\scriptsize hg19} & {\scriptsize Name of the reference genome used for alignment. UCSC
genome build hg19 was used}\tabularnewline
\hline 
\end{tabular}

\caption{\label{tab:explanation-of-bowtie-parameters}Explanation of bowtie
parameters}


\end{table}



\subsection{Importing into SeqMonk}

For analysis and quantitation of the e4C libraries, I used a program
called \emph{SeqMonk} \cite{Andrews2012}\emph{\@. }SeqMonk has been
developed by Dr. Simon Andrews, head of the Babraham Bioinformatics
team, and is written in Java with a graphical user interface. It has
been built from the ground up for analysis and visualisation of next
generation sequencing data, and has grown extensively throughout the
duration of my PhD.

SeqMonk works with aligned sequence reads, and can quantify them with
probes - custom windows set across the genome. Probes are simply sets
of paired genomic co-ordinates, and can be created over any feature
(such as gene or restriction fragment) or as running windows. These
probes are then used as bins within which reads can be quantified.


\section{Concerning raw data}


\subsection{Duplicate reads}

The first thing that can be seen when viewing the e4C libraries within
Seqmonk is the degree of sequence duplication. To generate enough
DNA to sequence the e4C libraries are amplified using PCR, however
this means that multiple copies of each 3C product may be sequenced.
It is clear that some quantitative information is present within the
numbers of reads found, as shown by the large number of reads surrounding
the bait region (Table \ref{tab:e4C-library-read-counts}). However,
because each e4C fragment end is defined by a restriction enzyme cut
site, duplicates from the 3C library are indistinguisable from duplicates
generated by the PCR amplification. Because of this inability to distinguish
biologically relevant duplicates from technical duplicates, I removed
all non-unique reads from the data.

\begin{table}
\begin{tabular}{|l|l|r|r|r|r|}
\hline 
 &  & {\scriptsize Total reads} & {\scriptsize Near }\emph{\scriptsize cis}{\scriptsize{} ($\leq$ 5
megabases)} & {\scriptsize Far }\emph{\scriptsize cis }{\scriptsize ($>$ 5 megabases)} & \emph{\scriptsize trans}\tabularnewline
\hline 
\hline 
\multirow{3}{*}{{\scriptsize BCR Run 1}} & {\scriptsize Raw} & {\scriptsize 14931033} & {\scriptsize 3986287 (26.7\%)} & {\scriptsize 1165115 (7.8\%)} & {\scriptsize 9779631 (65.5\%)}\tabularnewline
\cline{2-6} 
 & {\scriptsize De-duplicated} & {\scriptsize 10714} & {\scriptsize 1007 (9.4\%)} & {\scriptsize 873 (8.1\%)} & {\scriptsize 8834 (82.5\%)}\tabularnewline
\cline{2-6} 
 & {\scriptsize Av. dups / read}\emph{\scriptsize{} (per 10\textsuperscript{{\scriptsize 6}}
reads)} & {\scriptsize 1394}\emph{\scriptsize{} (93)} & {\scriptsize 3959 }\emph{\scriptsize (265)} & {\scriptsize 1335 }\emph{\scriptsize (89)} & {\scriptsize 1107 }\emph{\scriptsize (74)}\tabularnewline
\hline 
\multirow{3}{*}{{\scriptsize BCR Run 2}} & {\scriptsize Raw} & {\scriptsize 9260876} & {\scriptsize 3542934 (38.3\%)} & {\scriptsize 605320 (6.5\%)} & {\scriptsize 5112622 (55.2\%)}\tabularnewline
\cline{2-6} 
 & {\scriptsize De-duplicated} & {\scriptsize 8657} & {\scriptsize 935 (10.8\%)} & {\scriptsize 767 (8.9\%)} & {\scriptsize 6955 (80.3\%)}\tabularnewline
\cline{2-6} 
 & {\scriptsize Av. dups / read}\emph{\scriptsize{} (per 10\textsuperscript{{\scriptsize 6}}
reads)} & {\scriptsize 1070}\emph{\scriptsize{} (116)} & {\scriptsize 3789 }\emph{\scriptsize (409)} & {\scriptsize 789}\emph{\scriptsize{} (85)} & {\scriptsize 735 }\emph{\scriptsize (79)}\tabularnewline
\hline 
\multirow{3}{*}{{\scriptsize MLL Run 1}} & {\scriptsize Raw} & {\scriptsize 21923} & {\scriptsize 5030 (22.9\%)} & {\scriptsize 1821 (8.3\%)} & {\scriptsize 15072 (68.7\%)}\tabularnewline
\cline{2-6} 
 & {\scriptsize De-duplicated} & {\scriptsize 489} & {\scriptsize 54 (11.0\%)} & {\scriptsize 40 (8.2\%)} & {\scriptsize 395 (80.8\%)}\tabularnewline
\cline{2-6} 
 & {\scriptsize Av. dups / read}\emph{\scriptsize{} (per 10\textsuperscript{{\scriptsize 6}}
reads)} & {\scriptsize 45}\emph{\scriptsize{} (2045)} & {\scriptsize 93 }\emph{\scriptsize (4249)} & {\scriptsize 46}\emph{\scriptsize{} (2077)} & {\scriptsize 38 }\emph{\scriptsize (1740)}\tabularnewline
\hline 
\multirow{3}{*}{{\scriptsize MLL Run 2}} & {\scriptsize Raw} & {\scriptsize 13535278} & {\scriptsize 3236378 (23.9\%)} & {\scriptsize 1071434 (7.9\%)} & {\scriptsize 9227466 (68.2\%)}\tabularnewline
\cline{2-6} 
 & {\scriptsize De-duplicated} & {\scriptsize 1023} & {\scriptsize 107 (10.5\%)} & {\scriptsize 89 (8.7\%)} & {\scriptsize 827 (80.8\%)}\tabularnewline
\cline{2-6} 
 & {\scriptsize Av. dups / read}\emph{\scriptsize{} (per 10\textsuperscript{{\scriptsize 6}}
reads)} & {\scriptsize 13231}\emph{\scriptsize{} (978)} & {\scriptsize 30247 }\emph{\scriptsize (2235)} & {\scriptsize 12039 }\emph{\scriptsize (889)} & {\scriptsize 11158 }\emph{\scriptsize (824)}\tabularnewline
\hline 
\multirow{3}{*}{{\scriptsize MLL Run 3}} & {\scriptsize Raw} & {\scriptsize 8498056} & {\scriptsize 1701901 (20.0\%)} & {\scriptsize 808607 (9.5\%)} & {\scriptsize 5987548 (70.5\%)}\tabularnewline
\cline{2-6} 
 & {\scriptsize De-duplicated} & {\scriptsize 5589} & {\scriptsize 140 (2.5\%)} & {\scriptsize 269 (4.8\%)} & {\scriptsize 5180 (92.7\%)}\tabularnewline
\cline{2-6} 
 & {\scriptsize Av. dups / read}\emph{\scriptsize{} (per 10\textsuperscript{{\scriptsize 6}}
reads)} & {\scriptsize 1520 }\emph{\scriptsize (179)} & {\scriptsize 12156 }\emph{\scriptsize (1430)} & {\scriptsize 3006 }\emph{\scriptsize (354)} & {\scriptsize 1156 }\emph{\scriptsize (136)}\tabularnewline
\hline 
\multirow{3}{*}{{\scriptsize MLL Run 3 phiX}} & {\scriptsize Raw} & {\scriptsize 44194} & {\scriptsize 9054 (20.5\%)} & {\scriptsize 3891 (8.8\%)} & {\scriptsize 31249 (70.7\%)}\tabularnewline
\cline{2-6} 
 & {\scriptsize De-duplicated} & {\scriptsize 700} & {\scriptsize 83 (11.9\%)} & {\scriptsize 62 (8.9\%)} & {\scriptsize 555 (79.3\%)}\tabularnewline
\cline{2-6} 
 & {\scriptsize Av. dups / read}\emph{\scriptsize{} (per 10\textsuperscript{{\scriptsize 6}}
reads)} & {\scriptsize 63 }\emph{\scriptsize (1429)} & {\scriptsize 109 }\emph{\scriptsize (2468)} & {\scriptsize 63 }\emph{\scriptsize (1420)} & {\scriptsize 56 }\emph{\scriptsize (1274)}\tabularnewline
\hline 
\multirow{3}{*}{{\scriptsize ABL Run 1}} & {\scriptsize Raw} &  &  &  & \tabularnewline
\cline{2-6} 
 & {\scriptsize De-duplicated} &  &  &  & \tabularnewline
\cline{2-6} 
 & {\scriptsize Av. dups / read}\emph{\scriptsize{} (per 10\textsuperscript{{\scriptsize 6}}
reads)} &  &  &  & \tabularnewline
\hline 
\multirow{3}{*}{{\scriptsize MLL Promoter 1}} & {\scriptsize Raw} &  &  &  & \tabularnewline
\cline{2-6} 
 & {\scriptsize De-duplicated} &  &  &  & \tabularnewline
\cline{2-6} 
 & {\scriptsize Av. dups / read}\emph{\scriptsize{} (per 10\textsuperscript{{\scriptsize 6}}
reads)} &  &  &  & \tabularnewline
\hline 
\multirow{3}{*}{{\scriptsize MLL Promoter 2}} & {\scriptsize Raw} &  &  &  & \tabularnewline
\cline{2-6} 
 & {\scriptsize De-duplicated} &  &  &  & \tabularnewline
\cline{2-6} 
 & {\scriptsize Av. dups / read}\emph{\scriptsize{} (per 10\textsuperscript{{\scriptsize 6}}
reads)} &  &  &  & \tabularnewline
\hline 
\end{tabular}

\caption{\label{tab:e4C-library-read-counts}e4C library read counts}
\end{table}



\subsection{Read \emph{cis }/\emph{ trans }distribution}

The strongest predictor of physical sequence association is the linear
separation of the two fragments within their chromosome. If two regions
are in \emph{cis} their movement within three dimensional space relative
to each other is constrained by their linkage. This effect can clearly
be seen within all of the e4C libraries, with a large proportion of
my libraries (29 - 45\% raw reads) mapping to the \emph{cis} chromosome
(Table \ref{tab:e4C-library-read-counts}). The \emph{cis} association
is several orders of magnitude stronger than \emph{trans} association.

Because the e4C assay is based off 3C libraries, generated using \emph{AseI}
fragments, the greatest resolution that is possible is dependant on
the length of the digested fragments. If we reduce the association
data to binary observed / not observed \emph{AseI} fragments, the
close \emph{cis} interaction data can becomes saturated, especially
for the more complex \emph{BCR} datasets (Table \ref{tab:AseI-fragment-stats}).
Additionally, the genes of interest in my project - the oncogenic
translocation partners of \emph{BCR} and \emph{MLL} - are mostly in
\emph{trans}. In order to study these interactions without the \emph{cis}
interaction data overwhelming the analysis, I removed all \emph{cis}
interaction data from the datasets from further analysis.

\begin{table}[h]
\begin{tabular}{|l|r|r|r|r|}
\hline 
 & {\scriptsize Observed Fragments} & {\scriptsize Near }\emph{\scriptsize cis }{\scriptsize fragments ($\leq$
5 megabases)} & {\scriptsize Far }\emph{\scriptsize cis }{\scriptsize fragments ($>$
5 megabases)} & \emph{\scriptsize trans }{\scriptsize fragments}\tabularnewline
\hline 
\hline 
{\scriptsize BCR Run 1} & {\scriptsize 8612 (0.62\%)} & {\scriptsize 532 (43.36\%)} & {\scriptsize 666 (8.31\%)} & {\scriptsize 7414 (0.53\%)}\tabularnewline
\hline 
{\scriptsize BCR Run 2} & {\scriptsize 7612 (0.54\%)} & {\scriptsize 507 (41.32\%)} & {\scriptsize 610 (7.61\%)} & {\scriptsize 6495 (0.47\%)}\tabularnewline
\hline 
{\scriptsize MLL Run 1} & {\scriptsize 468 (0.03\%)} & {\scriptsize 45 (3.25\%)} & {\scriptsize 40 (0.07\%)} & {\scriptsize 383 (0.03\%)}\tabularnewline
\hline 
{\scriptsize MLL Run 2} & {\scriptsize 774 (0.06\%)} & {\scriptsize 62 (4.48\%)} & {\scriptsize 68 (0.11\%)} & {\scriptsize 644 (0.05\%)}\tabularnewline
\hline 
{\scriptsize MLL Run 3} & {\scriptsize 5176 (0.37\%)} & {\scriptsize 91 (6.58\%)} & {\scriptsize 236 (0.39\%)} & {\scriptsize 4849 (0.36\%)}\tabularnewline
\hline 
{\scriptsize MLL Run 3 PhiX} & {\scriptsize 673 (0.05\%)} & {\scriptsize 69 (4.99\%)} & {\scriptsize 62 (0.10\%)} & {\scriptsize 542 (0.04\%)}\tabularnewline
\hline 
{\scriptsize ABL} &  &  &  & \tabularnewline
\hline 
{\scriptsize MLL Promoter 1} &  &  &  & \tabularnewline
\hline 
{\scriptsize MLL Promoter 2} &  &  &  & \tabularnewline
\hline 
\hline 
{\scriptsize Possible }\emph{\scriptsize BCR} & {\scriptsize 1399460} & {\scriptsize 1227} & {\scriptsize 8013} & {\scriptsize 1390220}\tabularnewline
\hline 
{\scriptsize Possible }\emph{\scriptsize MLL} & {\scriptsize 1399460} & {\scriptsize 1384} & {\scriptsize 59813} & {\scriptsize 1338263}\tabularnewline
\hline 
\end{tabular}

\caption{\textbf{\label{tab:AseI-fragment-stats}}e4C library \emph{AseI} fragment
statistics}
\end{table}



\section{e4C library biases}

In 2011, a landmark paper was published by the group of Amos Tanay
describing new forms of analysis to be used with Hi-C interaction
datasets \cite{Yaffe2011a}. Yaffe \emph{et al.} showed biases present
within the Hi-C datasets towards higher GC content and particular
restriction fragment lengths. To investigate whether my e4C interaction
datasets were affected by the same biases, I wrote perl scripts to
compare the characteristics of the observed \emph{AseI} - \emph{NlaIII}
fragments versus all possible fragments.


\subsection{Potential fragment libraries \label{sub:Potential-fragment-libraries}}

A prerequesite for the analysis of these biases is the generation
of an \emph{in-silico} library of all potential fragments. The original
perl script to generate these libraries was written by Marek Piatek,
in the Babraham bioinformatics department. I have since re-written
the script from scratch, as well as writing other scripts to including
an online tool to generate lists of restriction enzyme recognition
sites (Appendix \ref{sec:APP-in-silico-restriction-fragments}). I
have made some of these available as online tools at \url{http://www.tallphil.co.uk/bioinformatics/ }
(Appendix \ref{chap:APP-Web-Tools}).

In principle, all of the scripts are similar - the genome is loaded
into memory one chromosome at a time, and perl's \emph{index} function
is used to search for the restriction enzyme recognition sites. For
\emph{AseI} - \emph{NlaIII} fragments, once an \emph{AseI} site is
found the next \emph{NlaIII} site is searched for. If one is found
before the next \emph{AseI} site, the resulting fragment length is
tested; if it is shorter than 35 base pairs or longer than 700 base
pairs then it is discarded due to the gel extraction size selection
used in the e4C protocol. The resulting library of fragments is then
aligned using \emph{Bowtie} and so filtered for unique mappability
(Table \ref{tab:in-silico-library-statistics}).

\begin{table}[h]
\begin{tabular}{|l|r|r|}
\cline{2-3} 
\multicolumn{1}{l|}{} & Fragments Removed & Total Fragments\tabularnewline
\hline 
All \emph{AseI} \textendash{} \emph{NlaIII} fragments & 0 & 2407346\tabularnewline
\hline 
Filter for length < 35bp & 283205 & 2124141 (88.24\%)\tabularnewline
\hline 
Filter for length > 700bp & 74398 & 2049743 (85.15\%)\tabularnewline
\hline 
Filter for unique mappability & 153862 & 1895881 (78.75\%)\tabularnewline
\hline 
\end{tabular}

\caption{\textbf{\emph{\label{tab:in-silico-library-statistics}}}\emph{in-silico}
potential AseI - NlaIII fragment\emph{ }library statistics}
\end{table}



\subsection{GC content bias and fragment length bias \label{sub:CH5-GC-content-bias}}

The \emph{in-silico} library described above was imported into SeqMonk
as an annotation track, and a probe created over each potential fragment.
A binary value was assigned to each fragment by using \emph{Minimum
Coverage Depth} quantitation. Results were exported as an annotated
probe report, containing the co-ordinates of every potential \emph{AseI}
- \emph{NlaIII} fragment with a binary flag to indicate whether it
was observed or not. I wrote a Perl script to process these datasets
(Appendix \ref{sec:APP-GC-content-bias}). The script fetches the
genomic sequence for each set of co-ordinates and increments counters
representing 5\% GC content bins, according to the \%GC content of
the sequence. A second set of counters were also incrememnted if the
sequence was observed. A modified version of this script was then
used to calculate \emph{AseI} - \emph{NlaIII} fragment lengths.

The resulting counts were plotted and can be seen in Figure \ref{fig:library-biases}.
It can be seen that the e4C libraries are biased towards greater \%GC
content and shorter fragments. These are likely to be experimental
biases that come from the ligation, PCR and sequencing steps. It should
be noted that the interaction libraries are enriched for GC rich regions
(Section \ref{sec:Active-genes-share-similar-global-interaction-profiles}),
so this bias may be a reflection of the specificity of the interaction
data.

\begin{figure}
\includegraphics[width=0.3\textwidth]{\string"figures/chapter 5/GC_length biases/GC_length biases\string".pdf}

\caption{\textbf{\label{fig:library-biases}}e4C library biases}


(A) GC bias in observed fragments (B) Fragment length bias in observed
fragments
\end{figure}



\subsubsection{Bias correction}

To correct the e4C libraries for systematic biases that are due to
GC content and fragment length, a library of all potential \emph{AseI}
- \emph{NlaIII} fragments was created with associated 'expected probability'
values. These were generated with a perl script which calculates a
correction value for each bin of GC \% and fragment length: (Appendix
\ref{sec:APP-systematic-bias-correction})

\[
C=\frac{hit\, fragments\, in\, bin}{hit\, fragments}\;/\;\frac{all\, fragments\, in\, bin}{all\, fragments}
\]


Then, for every potential fragment, the appropriate correction values
for \%GC and fragment length were multiplied against the overall chance
of any fragment being hit: 

\[
\rho_{frag}=\dfrac{observed\, fragments}{potential\, fragments}\times C_{\%GC}\times C_{frag\, length}
\]


This library of expected observation rates for every potential fragment
was then used in single window testing (Section \ref{sec:significance-of-single-regions}).



\subsubsection{Validation}

To check that the values produced by this script were reliable, I
wrote a small Perl script to generate \emph{in-silico }libraries using
the correction values. The script loops through every potential fragment
and outputs it as a hit if a random number between 0 and 1 is greater
than or equal to the correction factor. This was repeated 5 times
to generate a suitable number of reads. This \emph{in-silico} library
was then loaded into SeqMonk for visual inspection before being analysed
for biases as described in Section \ref{sub:CH5-GC-content-bias}.
The resulting plot shows the \emph{in-silico} library with identical
biases to the observed library, validating the correction values.


\section{\emph{AseI} site distribution normalisation}

Because e4C uses restriction fragments to analyse sequence proximity,
there is a chance that the unequal distribution of \emph{AseI} sites
across the genome could skew the results. To correct for this, I used
a Perl script written by Dr. Simon Andrews in the Babraham Bioinformatics
department. The script loads a list of potential fragments with binary
flags indicating whether they are observed or not, prepared as described
in Section \ref{sub:CH5-GC-content-bias}. It creates 100 Kb rolling
windows and counts the number of \emph{AseI} fragments present. If
there are greater than 5 fragments in a window, it calculates an ($\frac{observed}{potential}$)
value and outputs this to the results file. If there are less than
5 fragments it outputs 0; calculating percentages with such small
numbers of fragments can give uninformative values for regions with
few restriction sites, such as centromeres.

To allow the analysis of these percentage values within SeqMonk, I
wrote a Perl script to create a number of 'virtual reads' over each
100 Kb window according to the percentage score. These can then be
imported into SeqMonk and quantified by whatever method is desired.


\subsection{\emph{In-silico} testing}

To validate this normalisation, I wrote a Perl script which creates
randomised virtual e4C libraries from the list of potential \emph{AseI}
- \emph{NlaIII} fragments and loaded this into SeqMonk. I then ran
the \emph{AseI} normalisation as described above and loaded the resulting
normalised library back into SeqMonk.

\begin{figure}
\includegraphics[width=0.7\columnwidth]{\string"figures/chapter 5/AseI normalisation/AseI_normalisation\string".pdf}

\caption{\label{fig:AseI-normalisation}\emph{AseI} site distribution normalisation}


Chromosome 1 showing the \emph{in-silico} e4C randomised library before
and after normalisation for \emph{AseI} site distribution.
\end{figure}



\subsection{Standard scores}

To allow the comparison of different e4C libraries with varying degrees
of coverage, I typically converted and final quantification values
to \emph{standard scores}, also known as \emph{Z scores. }A standard
score represents how many standard deviations from the mean a single
value lies within a dataset. I initially calculated these values by
exporting data from SeqMonk and importing it into IBM SPSS Statistics.
The ability to requantify probes with standard scores has since been
built into SeqMonk.


\section{Significance of single regions \label{sec:significance-of-single-regions}}

Tests uses to determine significance for single windows.


\section{A genome wide approach}

Expanding the above approach to determine significance across the
entire genome.


\section{4C data set correlations}

Talk about the work I did doing pairwise correlation analysis on multiple
different 4C data sets..?


\section{Limitations of the e4C data}


\subsection{Coverage}

The problems of low coverage in the libraries, and how this differs
for the different bait regions. What we did to try to overcome this
(using GM12878 cells, using multiple bait regions). Why this makes
the data from the ABL1 and MLL baits have limited use.

Put this in the discussion chapter? 
\end{document}
